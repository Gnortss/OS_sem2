{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class UserItemData:\n    \n    def __init__(self,path,start_date=None,end_date=None,min_ratings=0):\n        self.data = pd.read_csv(path,sep=\"\\s+\")\n        \n        if start_date is not None: # Take into account start_date\n            d , m, y = start_date.strip().split(\".\")\n            self.data = self.data.loc[ (self.data[\"date_year\"]   >= int(y)) ]\n            self.data = self.data.loc[~((self.data[\"date_year\"] == int(y)) & (self.data[\"date_month\"] < int(m)))]\n            self.data = self.data.loc[~((self.data[\"date_year\"] == int(y)) & (self.data[\"date_month\"] == int(m)) & (self.data[\"date_day\"] < int(d)))]\n        \n        if end_date is not None: # Take into account end_date\n            d , m, y = end_date.strip().split(\".\")\n            self.data = self.data.loc[ (self.data[\"date_year\"] <= int(y)) ]\n            self.data = self.data.loc[~((self.data[\"date_year\"] == int(y)) & (self.data[\"date_month\"] > int(m)))]\n            self.data = self.data.loc[~((self.data[\"date_year\"] == int(y)) & (self.data[\"date_month\"] == int(m)) & (self.data[\"date_day\"] >= int(d)))]\n        \n        # Exclude movies with number of ratings < min_ratings\n        nr = self.data[\"movieID\"].value_counts()\n        self.data = self.data.loc[self.data[\"movieID\"].isin(nr.loc[(nr > min_ratings)].index.values)]\n        \n    def nratings(self):\n        return len(self.data.index)\n    \n    def movies_from_user(self, uid): # Returns all movies from user\n        user_mask = self.data[\"userID\"] == uid\n        return self.data[\"movieID\"].loc[user_mask]","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MovieData:\n    def __init__(self,path):\n        self.data =  pd.read_csv(path,sep=\"\\t+\",usecols=[\"id\",\"title\"],engine=\"python\")\n    \n    def get_title(self,id): # Tties to find the title of the given movie id\n        try:\n            return self.data[\"title\"].loc[self.data[\"id\"] == id].values[0]\n        except IndexError:\n            return None        ","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Recommender:\n    def __init__(self, predictor):\n        self.predictor = predictor\n        \n    def fit(self, X):\n        self.uim = X\n        self.predictor.fit(X)\n\n    def recommend(self, userID, n=10, rec_seen=True):\n        # Get predictions\n        preds = self.predictor.predict(userID)\n        # Sort predictions\n        rec_movies = sorted(preds.items(), key=lambda x: x[1], reverse=True)\n        if not rec_seen:\n            # Exclude seen movies\n            rec_movies = [m for m in rec_movies if m[0] not in self.uim.movies_from_user(userID).values]\n        return dict(rec_movies[:n]) # Return a slice of first n predictions","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RandomPredictor:\n    def __init__(self, min_grade=0, max_grade=5):\n        self.min = min_grade\n        self.max = max_grade\n        \n    def fit(self,X):\n        self.movies = X.data[\"movieID\"].values\n        \n    def predict(self,uid):\n        preds = dict()\n        for m in self.movies:\n            # Generate random grade for each movie\n            preds[m] = np.random.randint(self.min, self.max+1)\n        return preds","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class AveragePredictor:\n    def __init__(self, b):\n        self.b = b\n    \n    def fit(self, X):\n        self.data = X.data\n        \n    def predict(self, uid):\n        # Get the overall average (global average)\n        g_avg = self.data[\"rating\"].mean()\n        # Sum of ratings per movie\n        m_sum = self.data[[\"movieID\", \"rating\"]].groupby(\"movieID\").sum().rename(columns={\"rating\":\"sum\"})\n        # Number of ratings per movie\n        m_count = self.data[[\"movieID\", \"rating\"]].groupby(\"movieID\").count().rename(columns={\"rating\":\"count\"})\n        # Merge m_sum and m_count into dataframe\n        data = m_sum.merge(right=m_count, how='inner', left_index=True, right_index=True)\n        # Calculate an average for each movie(row in dataframe)\n        self.preds = data.apply(lambda x: pd.Series([(x['sum'] + self.b * g_avg)/(x['count']+self.b)], index=['ocena']), axis=1)\n        return dict(zip(self.preds.index, self.preds.ocena))","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ViewsPredictor:\n    def fit(self,X):\n        self.data = X.data\n        \n    def predict(self,uid):\n        # Just return number of ratings for each movie\n        return self.data[\"movieID\"].value_counts()","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class STDPredictor:\n    def __init__(self, n):\n        self.n = n\n    \n    def fit(self,X):\n        self.data = X.data\n        \n    def predict(self,uid):\n        # Create a mask for movies with number of ratings > self.n\n        nr = self.data[\"movieID\"].value_counts()\n        movies = nr.loc[(nr > self.n)].index\n        mask = self.data[\"movieID\"].isin(movies)\n        # Group by movieID and calculate standard deviation\n        self.preds = self.data[[\"movieID\",\"rating\"]].loc[mask].groupby(\"movieID\").std()[\"rating\"]\n        return self.preds","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ItemBasedPredictor:\n    def __init__(self, min_ratings=0, threshold=0):\n        self.mr = min_ratings\n        self.thr = threshold\n        \n    def get_most_similar_movies(self, n=20):\n        if not hasattr(self, 'sm'):\n            # Similarity matrix was not calculated yet @return empty list\n            return []\n        else:\n            sims = []\n            # Iterate through upper triangle (excludeing main diagonal) and collect all similarities\n            for i, row in enumerate(self.sm.index[:-1]):\n                for col in self.sm.columns[(i+1):]:\n                    sims.append((col, row, self.sm[col][row]))\n            # Sort similarities and slice only first n\n            return sorted(sims, key=lambda x: x[2], reverse=True)[:n]\n        \n    def similar_items(self, item, n):\n        if not hasattr(self, 'sm'):\n            # Similarity matrix was not calculated yet @return empty list\n            return []\n        else:\n            try:\n                # Sort similarities of given movie @return first n+1 (excluding the very first (similarity(item,item)))\n                return self.sm[item].sort_values(ascending=False)[1:(n+1)]\n            except KeyError:\n                # Movie not found in similarity matrix @return empty list\n                return []\n            \n    def similarity(self, m1, m2):\n        # @Return similarity between given movies\n        return self.sm[m1][m2]\n        \n    def build_similarity_matrix(self, m):\n        sm = pd.DataFrame(pd.DataFrame(), columns=m.columns, index=m.columns)\n        \n        for c1 in m.columns:\n            r1 = m[c1].dropna().rename(\"r1\")\n            for c2 in m.columns:\n                # inner join\n                r2 = m[c2].dropna().rename(\"r2\")\n                r12 = pd.merge(left=r1, right=r2, how='inner', left_index=True, right_index=True)\n                \n                if len(r12.index) < self.mr: # if not enough ratings then similarity is 0\n                    sm.at[c1, c2] = 0\n                    continue\n                \n                if c1 == c2: # if same columns then similarity is 1\n                    sm.at[c1, c2] = 1\n                    continue\n                \n                # similarity calculation\n                dot_product = r12[\"r1\"] @ r12[\"r2\"]\n                norm_1 = np.linalg.norm(r12[\"r1\"])\n                norm_2 = np.linalg.norm(r12[\"r2\"])\n                similarity = dot_product/(norm_1 * norm_2) if (norm_1 * norm_2) != 0 else 0\n                \n                # if below threshold then similarity is 0\n                sm.at[c1, c2] = similarity if similarity >= self.thr else 0\n        self.sm = sm\n    \n    def fit(self, X):\n        # Pivot table and normalize by subtracting ratings by their users average rating\n        mr = X.data.pivot_table(index=\"userID\", columns=\"movieID\", values=\"rating\")\n        mr['avg'] = mr.mean(axis=1)\n        self.urm = mr\n        norm = mr.sub(mr['avg'], axis=0)\n        del norm['avg']\n        self.urm_norm = norm\n        self.build_similarity_matrix(norm)   \n    \n    def predict(self, userID):\n        ra = self.urm['avg'][userID]\n        \n        user_rated_movies = self.urm.loc[userID, :][:-1].dropna().index # movies rated by userID\n        \n        self.preds = dict()\n        # Calculate prediction score for each movie\n        for m in self.urm.columns[:-1]: # score(userID, m)\n            s1 = 0\n            s2 = 0\n            for um in user_rated_movies:\n                s = self.similarity(m, um)\n                rating_scale = self.urm[um][userID] - ra\n                s1 += s*rating_scale\n                s2 += s\n            score = (s1/s2)+ra\n            self.preds[m] = score\n        return self.preds","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SlopeOnePredictor:\n    def fit(self, X):\n        # Pivot table\n        self.mr = X.data.pivot_table(index=\"userID\", columns=\"movieID\", values=\"rating\")\n    \n    def predict(self, userID):\n        # Get user rated and unrated movies\n        user_rated_movies = self.mr.loc[userID, :].dropna()\n        user_unrated_movies = self.mr.loc[userID, ~self.mr.loc[userID, :].notna()]\n        \n        preds = []\n        for unrated_movie in user_unrated_movies.index: # Predicting scores for unrated movies ...\n            score = 0\n            n = 0\n            mr1 = self.mr[unrated_movie].dropna().rename(\"r1\")\n            for rated_movie in user_rated_movies.index: # ...with help of rated movies\n                sub_score = self.mr.loc[userID, rated_movie]\n                mr2 = self.mr[rated_movie].dropna().rename(\"r2\")\n                \n                # Inner join on both movies -> only ratings from users who rated both movies\n                mr12 = pd.merge(left=mr1, right=mr2, how='inner', left_index=True, right_index=True)\n                diff = mr12[\"r1\"] - mr12[\"r2\"]\n                sub_score += diff.mean()\n                sub_score *= len(mr12.index)\n                n += len(mr12.index)\n                score += sub_score\n            score  = score/n if n != 0 else 0\n            preds.append(score)\n        to_append = pd.Series(preds, index=user_unrated_movies.index)\n        self.preds = user_rated_movies.append(to_append)\n        return dict(self.preds)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"md = MovieData('movielens/movies.dat')\nuim = UserItemData('movielens/user_ratedmovies.dat') ","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pr = AveragePredictor(100)\nrec = Recommender(pr)\nrec.fit(uim)\nrec_items = rec.recommend(78, n=5, rec_seen=False)\nprint(rec_items)\nfor idmovie, val in rec_items.items():\n    print(\"Film: {}, ocena: {}\".format(md.get_title(idmovie), val))","execution_count":28,"outputs":[{"output_type":"stream","text":"{50: 4.225944245560473, 1221: 4.146907937910189, 6016: 4.116538340205236, 58559: 4.10413904093503, 1203: 4.103639627096175}\nFilm: The Usual Suspects, ocena: 4.225944245560473\nFilm: The Godfather: Part II, ocena: 4.146907937910189\nFilm: Cidade de Deus, ocena: 4.116538340205236\nFilm: The Dark Knight, ocena: 4.10413904093503\nFilm: 12 Angry Men, ocena: 4.103639627096175\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pr = AveragePredictor(100)\nrec = Recommender(pr)\nrec.fit(uim)\n# rec_items = rec.recommend(78, n=5, rec_seen=False)\n# for idmovie, val in rec_items.items():\n#     print(\"Film: {}, ocena: {}\".format(md.get_title(idmovie), val))  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_ratings = [(20,4),(480,4.5),(1270,3.5),(6539,5),(1196,3.5),(260,3),(541,4),(2571,5),(8961,4),(1240,4),(589,5),(1036,5),\n             (1721,5),(648,3.5),(5349,3.5),(2628,3),(597,2),(1291,3.5),(457,4.5)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"uim_my = UserItemData('movielens/user_ratedmovies.dat', min_ratings=1000) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for movie, rating in my_ratings:\n    uim_my.data = uim_my.data.append([{\"userID\":1, \"movieID\": movie, \"rating\":rating,\n                                \"date_day\": 1, \"date_month\": 1, \"date_year\": 2021, \"date_hour\": 1,\n                                \"date_minute\": 1, \"date_second\": 1}], ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pr = ItemBasedPredictor()\nrec = Recommender(pr)\nrec.fit(uim_my)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rec_items = rec.recommend(1, n=10, rec_seen=False)\nfor idmovie, val in rec_items.items():\n    print(\"Film {}: {}, ocena: {}\".format(idmovie, md.get_title(idmovie), val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pr = SlopeOnePredictor()\nrec = Recommender(pr)\nrec.fit(uim)\n\nprint(\"Predictions for 78: \")\nrec_items = rec.recommend(78, n=15, rec_seen=False)\nfor idmovie, val in rec_items.items():\n    print(\"Film {}: {}, ocena: {}\".format(idmovie, md.get_title(idmovie), val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}